{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "In this assignment, we will implement a simplified version of object detection process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage import io\n",
    "from skimage.feature import hog\n",
    "from skimage import data, color, exposure\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import glob, os\n",
    "import fnmatch\n",
    "import time\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from detection import *\n",
    "from util import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 1: Hog Representation (1 point)\n",
    "\n",
    "In this section, we will compute the average hog representation of human faces.<br>\n",
    "There are 31 aligned face images provided in the `\\face` folder. They are all aligned and have the same size. We will get an average face from these images and compute a hog feature representation for the averaged face, which is treated as the face model. Note that, in practice, we get the face model by training a SVM classifier on a separate dataset of face vs non-face images. This step has been described in the lectrue 18. However, due to the scope of assignment, this step had been greatly simplified to only compute the hog representation of average face<br>\n",
    "Use the hog function provided by skimage library, and implement a hog representation of objects.\n",
    "Implement **`hog_feature`** function in `detection.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = fnmatch.filter(os.listdir('./face'), '*.jpg')\n",
    "list.sort(image_paths)\n",
    "n = len(image_paths)\n",
    "face_shape = io.imread('./face/'+image_paths[0], as_grey=True).shape\n",
    "avg_face= np.zeros((face_shape))\n",
    "for i,image_path in enumerate(image_paths):\n",
    "    image = io.imread('./face/'+image_path, as_grey=True)\n",
    "    avg_face = np.asarray(image)+np.asarray(avg_face)\n",
    "avg_face = avg_face/n\n",
    "\n",
    "(face_feature, face_hog) = hog_feature(avg_face)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(avg_face)\n",
    "plt.axis('off')\n",
    "plt.title('average face image')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(face_hog)\n",
    "plt.title('hog representation of face')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Sliding Window (2 points)\n",
    "Implement **`sliding_window`** function to have windows slide across an image with a specific window size. The window slides through the image and check if an object is detected with a high score at every location. These scores will generate a response map and you will be able to find the location of the window with the highest hog score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'image_0001.jpg'\n",
    "\n",
    "image = io.imread(image_path, as_grey=True)\n",
    "image = rescale(image, 0.8)\n",
    "\n",
    "(hogFeature, hogImage) = hog_feature(image)\n",
    "\n",
    "(winH, winW) = face_shape\n",
    "(score, r, c, response_map) = sliding_window(image, face_feature, stepSize=30, windowSize=face_shape)\n",
    "crop = image[r:r+winH, c:c+winW]\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(image)\n",
    "rect = patches.Rectangle((c,r),winW,winH,linewidth=1,edgecolor='r',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(response_map,cmap='viridis', interpolation='nearest')\n",
    "plt.title('sliding window')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sliding window successfully found the human face in the above example. However, in the cell below, we are only changing the scale of the image, and you can see that sliding window does not work once the scale of the image is changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'image_0001.jpg'\n",
    "image = io.imread(image_path, as_grey=True)\n",
    "image = rescale(image, 1.0)\n",
    "\n",
    "\n",
    "(winH, winW) = face_shape\n",
    "(score, r, c, max_response_map) = sliding_window(image, face_feature, stepSize=30, windowSize=face_shape)\n",
    "\n",
    "crop = image[r:r+winH, c:c+winW]\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(image)\n",
    "rect = patches.Rectangle((c,r),winW,winH,linewidth=1,edgecolor='r',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(max_response_map,cmap='viridis', interpolation='nearest')\n",
    "plt.title('sliding window')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Image Pyramids (2 points)\n",
    "In order to make sliding window work for different scales of images, you need to implement image pyramids where you resize the image to different scales and run the sliding window method on each resized image. This way you scale the objects and can detect both small and large objects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.1 Image Pyramid (0.5 point)\n",
    "\n",
    "Implement **`pyramid`** function in `detection.py`, this will create pyramid of images at different scales. Run the following code, and you will see the shape of the original image gets smaller until it reaches a minimum size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'image_0001.jpg'\n",
    "\n",
    "image = io.imread(image_path, as_grey=True)\n",
    "image = rescale(image, 1.2)\n",
    "\n",
    "images = pyramid(image, scale = 0.9)\n",
    "sum_r = 0\n",
    "sum_c = 0\n",
    "for i,result in enumerate(images):\n",
    "    (scale, image) = result\n",
    "    if (i==0):\n",
    "        sum_c = image.shape[1]\n",
    "    sum_r+=image.shape[0]\n",
    "\n",
    "composite_image = np.zeros((sum_r, sum_c))\n",
    "\n",
    "pointer = 0\n",
    "for i, result in enumerate(images):\n",
    "    (scale, image) = result   \n",
    "    composite_image[pointer:pointer+image.shape[0], :image.shape[1]] = image\n",
    "    pointer+= image.shape[0]\n",
    "    \n",
    "plt.imshow(composite_image)\n",
    "plt.axis('off')\n",
    "plt.title('image pyramid')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.2 Pyramid Score (1 points)\n",
    "\n",
    "After getting the image pyramid, we will run sliding window on all the images to find a place that gets the highest score. Implement **`pyramid_score`** function in `detection.py`. It will return the highest score and its related information in the image pyramids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'image_0001.jpg'\n",
    "\n",
    "image = io.imread(image_path, as_grey=True)\n",
    "image = rescale(image, 1.2)\n",
    "\n",
    "(winH, winW) = face_shape\n",
    "max_score, maxr, maxc, max_scale, max_response_map = pyramid_score \\\n",
    "        (image, face_feature, face_shape, stepSize = 30, scale=0.8)\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(rescale(image, max_scale))\n",
    "rect = patches.Rectangle((maxc,maxr),winW,winH,linewidth=1,edgecolor='r',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(max_response_map, cmap='viridis', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above example, we can see that image pyramid has fixed the problem of scaling. Then in the example below, we will try another image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'image_0338.jpg'\n",
    "image = io.imread(image_path, as_grey=True)\n",
    "image = rescale(image, 1.0)\n",
    "\n",
    "(winH, winW) = face_shape\n",
    "\n",
    "max_score, maxr, maxc, max_scale, max_response_map = pyramid_score \\\n",
    "    (image, face_feature, face_shape, stepSize = 30, scale=0.8)\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(rescale(image, max_scale))\n",
    "rect = patches.Rectangle((maxc,maxr),winW,winH,linewidth=1,edgecolor='r',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(max_response_map,cmap='viridis', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can also detect the face successfully. Then, how about this image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'image_0319.jpg'\n",
    "image = io.imread(image_path, as_grey=True)\n",
    "image = rescale(image, 1.0)\n",
    "\n",
    "(winH, winW) = face_shape\n",
    "\n",
    "max_score, maxr, maxc, max_scale, max_response_map = pyramid_score \\\n",
    "    (image, face_feature, face_shape, stepSize = 30, scale=0.8)\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(rescale(image, max_scale))\n",
    "rect = patches.Rectangle((maxc,maxr),winW,winH,linewidth=1,edgecolor='r',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(max_response_map,cmap='viridis', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Question (0.5 point)\n",
    "\n",
    "Seems that the face in the above example is not detected correctly anymore. What is the problem here? Suggest at least one approach to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:** Write your answer in this markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit**: Juan Carlos Niebles and Ranjay Krishna"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
